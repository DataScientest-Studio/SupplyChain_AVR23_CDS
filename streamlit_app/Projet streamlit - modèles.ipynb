{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07331cc2",
   "metadata": {},
   "source": [
    "# Projet streamlit - Partie Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9bf6f",
   "metadata": {},
   "source": [
    "## Projet Supply Chain - DSAvril23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3958838",
   "metadata": {},
   "source": [
    "## 1. Import des packages et données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4297c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6577eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\MAMERLE\\OneDrive - Eiffage\\Documents\\IA_Supply_chain\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import pickle\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "975a7b80-2ae3-422a-bbc8-7b046ef6d099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mamerle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\mamerle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\mamerle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mamerle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mamerle\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Using cached imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.11.0 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5225f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d2dab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cellule à relancer lors de la prochaine ré-ouverture du notebook\n",
    "df=pd.read_csv('Compilation webscrapping cosmetique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fad888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dans cette partie modélisation, seules les variables commentaires et notes nous intéressent\n",
    "# transformation du type de la note\n",
    "df['notes']=df['notes'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5813202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde de notre dataframe que les commentaires (variable explicative) et les notes (variable à prédire)\n",
    "X, y = df.commentaire, df.notes\n",
    "\n",
    "# Séparation des données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Définition de l'objet CountVectorizer() et du GradientBoostingClassifier()\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3684174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement de l'objet vectorizer\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb9508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes échantillon SMOTE : {1: 2667, 5: 2667, 4: 2667, 2: 2667, 3: 2667}\n"
     ]
    }
   ],
   "source": [
    "smo = SMOTE()\n",
    "X_sm, y_sm = smo.fit_resample(X_train, y_train)\n",
    "print('Classes échantillon SMOTE :', dict(pd.Series(y_sm).value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6964b",
   "metadata": {},
   "source": [
    "## 2. Random forest avec smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0237c423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du Random Forest sont :\n",
      " {'max_features': 'log2', 'min_samples_split': 26}\n",
      "Le classification report du modèle rfc sur les données d'entrainement est :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.96      0.91      1287\n",
      "           2       1.00      0.13      0.24       164\n",
      "           3       1.00      0.09      0.17       132\n",
      "           4       1.00      0.17      0.28       315\n",
      "           5       0.87      1.00      0.93      2659\n",
      "\n",
      "    accuracy                           0.87      4557\n",
      "   macro avg       0.95      0.47      0.50      4557\n",
      "weighted avg       0.89      0.87      0.83      4557\n",
      "\n",
      "Le classification report du modèle rfc sur les données de test est :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.81      0.80       299\n",
      "           2       0.00      0.00      0.00        38\n",
      "           3       0.00      0.00      0.00        45\n",
      "           4       0.00      0.00      0.00        90\n",
      "           5       0.79      0.98      0.87       668\n",
      "\n",
      "    accuracy                           0.79      1140\n",
      "   macro avg       0.32      0.36      0.34      1140\n",
      "weighted avg       0.67      0.79      0.72      1140\n",
      "\n",
      "La matrice de confusion sur l'ensemble de test est :\n",
      " col_0    1    5\n",
      "notes          \n",
      "1      243   56\n",
      "2       22   16\n",
      "3       18   27\n",
      "4       11   79\n",
      "5       11  657\n"
     ]
    }
   ],
   "source": [
    "## RANDOM FOREST SUR JEU COMPLET APRES SMOTE\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "params_rfc = {\"max_features\":[\"sqrt\",\"log2\",None], \"min_samples_split\" : [x for x in range(2,31) if x%2 ==0]}\n",
    "grid_rfc = GridSearchCV(estimator=rfc, param_grid=params_rfc, cv=3)\n",
    "grid_rfc.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres du Random Forest\n",
    "print(\"Les meilleurs paramètres du Random Forest sont :\\n\", grid_rfc.best_params_)\n",
    "\n",
    "y_pred_rfc_train = grid_rfc.predict(X_train)\n",
    "y_pred_rfc_test = grid_rfc.predict(X_test)\n",
    "\n",
    "# Afficher le classification report du modèle rfc sur les données d'entrainement\n",
    "print(\"Le classification report du modèle rfc sur les données d'entrainement est :\\n\", classification_report(y_train, y_pred_rfc_train))\n",
    "\n",
    "# Afficher le classification report du modèle rfc sur les données de test\n",
    "print(\"Le classification report du modèle rfc sur les données de test est :\\n\", classification_report(y_test, y_pred_rfc_test))\n",
    "\n",
    "# Afficher la matrice de confusion sur l'ensemble de test\n",
    "print(\"La matrice de confusion sur l'ensemble de test est :\\n\", pd.crosstab(y_test, y_pred_rfc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b75f4b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du modèle rfc\n",
    "with open('random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_rfc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019202fb",
   "metadata": {},
   "source": [
    "## 3. SVC avec smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d1f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs paramètres du SVC sont :\n",
      " {'C': 10, 'kernel': 'rbf'}\n",
      "Le classification report du modèle SVC sur les données d'entrainement est :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.97      0.98      1287\n",
      "           2       1.00      0.94      0.97       164\n",
      "           3       1.00      0.92      0.96       132\n",
      "           4       1.00      0.72      0.84       315\n",
      "           5       0.95      1.00      0.97      2659\n",
      "\n",
      "    accuracy                           0.97      4557\n",
      "   macro avg       0.99      0.91      0.95      4557\n",
      "weighted avg       0.97      0.97      0.97      4557\n",
      "\n",
      "Le classification report du modèle SVC sur les données de test est :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.90      0.83       299\n",
      "           2       0.25      0.05      0.09        38\n",
      "           3       0.20      0.02      0.04        45\n",
      "           4       0.32      0.08      0.12        90\n",
      "           5       0.85      0.96      0.90       668\n",
      "\n",
      "    accuracy                           0.81      1140\n",
      "   macro avg       0.48      0.40      0.40      1140\n",
      "weighted avg       0.74      0.81      0.76      1140\n",
      "\n",
      "La matrice de confusion sur l'ensemble de test est :\n",
      " col_0    1  2  3  4    5\n",
      "notes                   \n",
      "1      268  2  1  1   27\n",
      "2       26  2  1  2    7\n",
      "3       21  1  1  6   16\n",
      "4       16  2  1  7   64\n",
      "5       18  1  1  6  642\n"
     ]
    }
   ],
   "source": [
    "## SVC SUR JEU COMPLET APRES SMOTE\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "params_svc = {\"kernel\":[\"linear\",\"sigmoid\",\"rbf\"], \"C\" : [0.1, 1, 10, 30]}\n",
    "grid_svc=GridSearchCV(estimator = svc, param_grid = params_svc, cv=5)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "\n",
    "# Afficher les meilleurs paramètres du SVC\n",
    "print(\"Les meilleurs paramètres du SVC sont :\\n\", grid_svc.best_params_)\n",
    "\n",
    "y_pred_svc_train = grid_svc.predict(X_train)\n",
    "y_pred_svc_test = grid_svc.predict(X_test)\n",
    "    \n",
    "# Afficher le classification report du modèle SVC sur les données d'entrainement\n",
    "print(\"Le classification report du modèle SVC sur les données d'entrainement est :\\n\", classification_report(y_train, y_pred_svc_train))\n",
    "\n",
    "# Afficher le classification report du modèle SVC sur les données de test\n",
    "print(\"Le classification report du modèle SVC sur les données de test est :\\n\", classification_report(y_test, y_pred_svc_test))\n",
    "\n",
    "# Afficher la matrice de confusion sur l'ensemble de test\n",
    "print(\"La matrice de confusion sur l'ensemble de test est :\\n\", pd.crosstab(y_test, y_pred_svc_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb8e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du modèle svc\n",
    "with open('svc_model.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_svc, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dbe665",
   "metadata": {},
   "source": [
    "## 4. Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a5a51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AttributeError: Can only use .cat accessor with a 'category' dtype\n",
    "df=pd.read_csv('Compilation webscrapping cosmetique.csv')\n",
    "df['notes']=df['notes'].astype('int')\n",
    "df['notes'] = df['notes'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebca7568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 50)           50000     \n",
      "                                                                 \n",
      " spatial_dropout1d_3 (Spati  (None, 100, 50)           0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 505       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110905 (433.22 KB)\n",
      "Trainable params: 110905 (433.22 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Le summary du modèle d'Embedding est :\n",
      " None\n",
      "Epoch 1/5\n",
      "114/114 [==============================] - 8s 57ms/step - loss: 0.9324 - accuracy: 0.6834 - val_loss: 0.6630 - val_accuracy: 0.8191\n",
      "Epoch 2/5\n",
      "114/114 [==============================] - 6s 49ms/step - loss: 0.6070 - accuracy: 0.8159 - val_loss: 0.5667 - val_accuracy: 0.8344\n",
      "Epoch 3/5\n",
      "114/114 [==============================] - 6s 50ms/step - loss: 0.5437 - accuracy: 0.8354 - val_loss: 0.5617 - val_accuracy: 0.8322\n",
      "Epoch 4/5\n",
      "114/114 [==============================] - 6s 50ms/step - loss: 0.5075 - accuracy: 0.8414 - val_loss: 0.5425 - val_accuracy: 0.8311\n",
      "Epoch 5/5\n",
      "114/114 [==============================] - 6s 49ms/step - loss: 0.4712 - accuracy: 0.8508 - val_loss: 0.5660 - val_accuracy: 0.8300\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.5669 - accuracy: 0.8307\n",
      "L accuracy sur notre jeu de test est :  0.8307017683982849\n"
     ]
    }
   ],
   "source": [
    "## EMBEDDING SUR JEU COMPLET\n",
    "\n",
    "X, y = df.commentaire, df.notes\n",
    "\n",
    "# Séparation des données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "num_classes = len(df['notes'].cat.categories)\n",
    "max_words = 1000  \n",
    "max_len = 100 \n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_text = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_text = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "train_text = pad_sequences(X_train_text, maxlen=max_len)\n",
    "test_text = pad_sequences(X_test_text, maxlen=max_len)\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Afficher le summary du modèle d'Embedding\n",
    "print(\"Le summary du modèle d'Embedding est :\\n\", model.summary()) \n",
    "    \n",
    "y_train_cat = to_categorical(y_train.cat.codes)\n",
    "y_test_cat = to_categorical(y_test.cat.codes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "model.fit(train_text, y_train_cat, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(test_text, y_test_cat)\n",
    "print(\"L accuracy sur notre jeu de test est : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a4c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du modèle d'embedding\n",
    "model.save('embedding_model.h5') #ne fonctionne pas avec pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7079e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
